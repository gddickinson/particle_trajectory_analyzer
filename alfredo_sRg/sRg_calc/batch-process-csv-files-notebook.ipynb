{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Process CSV Files for sRg Calculation\n",
    "\n",
    "This notebook processes multiple CSV files in a specified directory, calculating sRg and classification values for trajectory data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "library(tools)\n",
    "\n",
    "# Source the file containing trajectory feature calculation functions\n",
    "source('featuresCalcsNew.R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "cutoffLen <- 3  # minimum trajectory length\n",
    "cutoff <- 2.22236433588659  # immobile/mobile threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the csv file is assumed to have the following columns:\n",
    "#,track_number,frame,x,y,intensity,id,x [nm],y [nm]\n",
    "# the header is assumed to be present\n",
    "# GD - the numbering system has to match R (start from 1) for both track_number and frame and have sequential tracks (no missing) otherwise things go wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single CSV file\n",
    "process_csv_file <- function(file_path) {\n",
    "  # Read the CSV file\n",
    "  df <- read.csv(file_path, header = TRUE)\n",
    "    \n",
    "  # Split data by track_number\n",
    "  things <- split(df[, c('frame', 'x', 'y')], df$track_number)\n",
    "  \n",
    "  # Select tracks above the length cutoff\n",
    "  lens <- sapply(things, nrow)\n",
    "  sel <- which(lens >= cutoffLen)\n",
    "  lsel <- length(sel)\n",
    "  cat(paste(\"Processing\", file_path, \"-\", lsel, \"tracks extracted of length >=\", cutoffLen, \"\\n\"))\n",
    "  \n",
    "  # Compute sRg for selected tracks\n",
    "  sRgL <- vector(mode = \"list\", length = lsel)\n",
    "  for (i in seq_along(sel)) {\n",
    "    mymat <- things[[sel[i]]]\n",
    "    tmat <- matrix(nrow = mymat[nrow(mymat), 'frame'] - mymat[1, 'frame'] + 1, ncol = 2)\n",
    "    tmat[mymat[, 1] - mymat[1, 1] + 1, 1] <- mymat[, 2]\n",
    "    tmat[mymat[, 1] - mymat[1, 1] + 1, 2] <- mymat[, 3]\n",
    "    sRgL[[i]] <- getsRg(tmat)\n",
    "  }\n",
    "  sRg <- unlist(sRgL)\n",
    "  \n",
    "  # Threshold classification\n",
    "  myclass <- ifelse(sRg < cutoff, 'immobile', 'mobile')\n",
    "  \n",
    "  # Create a data frame with track numbers, sRg values, and classifications\n",
    "  sRg_data <- data.frame(track_number = sel, sRg = sRg, classification = myclass)\n",
    "  \n",
    "  # Merge the original data with the new sRg and classification data\n",
    "  merged_df <- merge(df, sRg_data, by.x = \"track_number\", by.y = \"track_number\", all.x = TRUE)\n",
    "  \n",
    "  # Sort the dataframe to ensure it's in the original order\n",
    "  merged_df <- merged_df[order(merged_df$track_number, merged_df$frame), ]\n",
    "  \n",
    "  # Create the new filename with '_sRg' tag\n",
    "  new_filename <- file_path_sans_ext(file_path)\n",
    "  new_filename <- paste0(new_filename, \"_sRg.csv\")\n",
    "  \n",
    "  # Save the new CSV file\n",
    "  write.csv(merged_df, file = new_filename, row.names = FALSE)\n",
    "  \n",
    "  cat(paste(\"New file saved as:\", new_filename, \"\\n\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process all CSV files in a directory\n",
    "process_directory <- function(directory_path) {\n",
    "  # List all CSV files in the directory\n",
    "  csv_files <- list.files(directory_path, pattern = \"\\\\.csv$\", full.names = TRUE)\n",
    "  \n",
    "  # Process each CSV file\n",
    "  for (file in csv_files) {\n",
    "    tryCatch({\n",
    "      process_csv_file(file)\n",
    "    }, error = function(e) {\n",
    "      cat(paste(\"Error processing file:\", file, \"\\n\"))\n",
    "      cat(paste(\"Error message:\", e$message, \"\\n\"))\n",
    "    })\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/george/Desktop/tdt_analysis/for_Alan/differntRecordingLengths/2s/for_sRg/AL_55_2020-06-29-TIRFM_Diff_tdt-MEFs_C_2_MMStack_Pos0_crop20_locsID_tracksRG_SVMPredicted_NN_forR.csv - 5167 tracks extracted of length >= 3 \n",
      "New file saved as: /Users/george/Desktop/tdt_analysis/for_Alan/differntRecordingLengths/2s/for_sRg/AL_55_2020-06-29-TIRFM_Diff_tdt-MEFs_C_2_MMStack_Pos0_crop20_locsID_tracksRG_SVMPredicted_NN_forR_sRg.csv \n",
      "Processing /Users/george/Desktop/tdt_analysis/for_Alan/differntRecordingLengths/2s/for_sRg/AL_56_2020-07-01-TIRFM_Diff_tdt-MEFs_A_4_MMStack_Pos0_crop20_locsID_tracksRG_SVMPredicted_NN_forR.csv - 4577 tracks extracted of length >= 3 \n",
      "New file saved as: /Users/george/Desktop/tdt_analysis/for_Alan/differntRecordingLengths/2s/for_sRg/AL_56_2020-07-01-TIRFM_Diff_tdt-MEFs_A_4_MMStack_Pos0_crop20_locsID_tracksRG_SVMPredicted_NN_forR_sRg.csv \n",
      "Processing /Users/george/Desktop/tdt_analysis/for_Alan/differntRecordingLengths/2s/for_sRg/AL_66_2020-07-28-TIRFM_Diff_tdt-MEFs_A_3_MMStack_Pos0_crop20_locsID_tracksRG_SVMPredicted_NN_forR.csv - 5959 tracks extracted of length >= 3 \n",
      "New file saved as: /Users/george/Desktop/tdt_analysis/for_Alan/differntRecordingLengths/2s/for_sRg/AL_66_2020-07-28-TIRFM_Diff_tdt-MEFs_A_3_MMStack_Pos0_crop20_locsID_tracksRG_SVMPredicted_NN_forR_sRg.csv \n",
      "Batch processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "# Prompt user for directory path\n",
    "directory_path <-\"/Users/george/Desktop/tdt_analysis/for_Alan/differntRecordingLengths/2s/for_sRg\"\n",
    "\n",
    "# Check if the directory exists\n",
    "if (!dir.exists(directory_path)) {\n",
    "  stop(\"The specified directory does not exist.\")\n",
    "}\n",
    "\n",
    "# Process all CSV files in the directory\n",
    "process_directory(directory_path)\n",
    "\n",
    "cat(\"Batch processing complete.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
